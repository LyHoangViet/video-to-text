import os
import boto3
import base64
import json
import streamlit as st
from typing import List
from botocore.exceptions import ClientError
import tempfile
import cv2
from PIL import Image
import io
import enum

# Import t·ª´ module video_processor
from video_processor import VideoProcessor

st.set_page_config(
    page_title="Ph√¢n T√≠ch Video S·∫£n Ph·∫©m V·ªõi Bedrock",
    page_icon="üîç",
    layout="wide"
)

# Khai b√°o m·∫∑c ƒë·ªãnh cho prompt v√† c√°c th√¥ng s·ªë model
DEFAULT_PROMPT = """D·ª±a v√†o list h√¨nh t·ª´ video n√†y, b·∫°n h√£y:

1. X√°c ƒë·ªãnh t·∫•t c·∫£ c√°c lo·∫°i s·∫£n ph·∫©m kh√°c nhau xu·∫•t hi·ªán trong h√¨nh (d·ª±a v√†o m√†u s·∫Øc bao b√¨, thi·∫øt k·∫ø v√† t√™n s·∫£n ph·∫©m).

2. ƒê·∫øm s·ªë l∆∞·ª£ng s·∫£n ph·∫©m c·ªßa m·ªói lo·∫°i.

3. T·ªïng h·ª£p th√¥ng tin v·ªõi:
   - S·ªë lo·∫°i s·∫£n ph·∫©m kh√°c nhau
   - S·ªë l∆∞·ª£ng c·ªßa m·ªói lo·∫°i
   - T·ªïng s·ªë s·∫£n ph·∫©m
   
4. M√¥ t·∫£ ng·∫Øn g·ªçn ƒë·∫∑c ƒëi·ªÉm nh·∫≠n d·∫°ng ch√≠nh c·ªßa m·ªói lo·∫°i s·∫£n ph·∫©m ƒë·ªÉ ph√¢n bi·ªát."""

DEFAULT_TEMPERATURE = 0.1
DEFAULT_TOP_P = 0.2
DEFAULT_TOP_K = 50
DEFAULT_MAX_TOKENS = 4000
DEFAULT_REGION = "us-east-1"  # S·ª≠ d·ª•ng region m·∫∑c ƒë·ªãnh

# ƒê·ªãnh nghƒ©a enum cho c√°c model
class ModelType(str, enum.Enum):
    NOVA = "Amazon Nova"
    CLAUDE = "Claude 3.7 Sonnet"

def detect_image_type(file_name: str) -> str:
    """
    Detects the image MIME type based on file extension.
    
    Args:
        file_name: Name of the image file
        
    Returns:
        MIME type string for the image
    """
    extension = os.path.splitext(file_name)[1].lower()
    
    mime_types = {
        ".jpg": "jpeg",
        ".jpeg": "jpeg",
        ".png": "png",
        ".gif": "gif",
        ".webp": "webp",
        ".bmp": "bmp"
    }
    
    return mime_types.get(extension, "jpeg")

def image_to_base64(image, image_name="frame.jpg"):
    """
    Chuy·ªÉn ƒë·ªïi ·∫£nh (PIL Image ho·∫∑c numpy array) th√†nh chu·ªói base64.
    
    Args:
        image: ·∫¢nh d·∫°ng PIL Image ho·∫∑c numpy array
        image_name: T√™n ·∫£nh ƒë·ªÉ x√°c ƒë·ªãnh ki·ªÉu MIME
        
    Returns:
        Tuple (chu·ªói base64, ki·ªÉu MIME)
    """
    # N·∫øu l√† numpy array (t·ª´ OpenCV), chuy·ªÉn th√†nh PIL Image
    if isinstance(image, (list, tuple, bytes, bytearray)):
        # ƒê√£ l√† bytes ho·∫∑c bytearray
        img_bytes = image
    elif hasattr(image, 'shape'):  # Numpy array
        img_pil = Image.fromarray(image)
        buf = io.BytesIO()
        img_pil.save(buf, format='JPEG')
        img_bytes = buf.getvalue()
    else:  # PIL Image
        buf = io.BytesIO()
        image.save(buf, format='JPEG')
        img_bytes = buf.getvalue()
        
    # Encode base64
    base64_encoded = base64.b64encode(img_bytes).decode('utf-8')
    mime_type = detect_image_type(image_name)
    
    return base64_encoded, mime_type

def analyze_frames_with_nova(frames, prompt: str, temperature: float, top_p: float, top_k: int, max_tokens: int):
    """
    Uses Amazon Nova on AWS Bedrock to analyze video frames and count different types of products.
    
    Args:
        frames: List of video frames to analyze
        prompt: Custom prompt for Nova
        temperature: Temperature setting (0-1)
        top_p: Top-p setting (0-1)
        top_k: Top-k setting
        max_tokens: Maximum tokens in response
        
    Returns:
        Nova's analysis of the video frame content
    """
    
    # Create placeholder for loading indicator
    with st.spinner("Nova ƒëang ph√¢n t√≠ch frames t·ª´ video..."):
        # System prompt
        system_list = [
            {
                "text": "You are an expert at analyzing product images and videos. You can identify different types of products, count them, and describe their key features."
            }
        ]
        
        # Prepare user message with images and text prompt
        user_content = []
        
        # Add images to user content
        for i, (_, frame) in enumerate(frames):
            # Encode to base64
            image_data, mime_type = image_to_base64(frame, f"frame_{i}.jpg")
            
            # Add image to user content
            user_content.append({
                "image": {
                    "format": mime_type,
                    "source": {"bytes": image_data}
                }
            })
        
        # Add text prompt to user content
        user_content.append({"text": prompt})
        
        # Create message list
        message_list = [
            {
                "role": "user",
                "content": user_content
            }
        ]
        
        # Configure inference parameters
        inf_params = {
            "maxTokens": max_tokens,
            "topP": top_p,
            "topK": top_k,
            "temperature": temperature
        }
        
        # Prepare the request payload for Nova on Bedrock
        payload = {
            "schemaVersion": "messages-v1",
            "messages": message_list,
            "system": system_list,
            "inferenceConfig": inf_params
        }
        
        try:
            # Create a Bedrock Runtime client
            # S·ª≠ d·ª•ng region m·∫∑c ƒë·ªãnh v√† credentials t·ª´ m√¥i tr∆∞·ªùng
            bedrock_runtime = boto3.client(
                service_name="bedrock-runtime",
                region_name=DEFAULT_REGION
            )
            
            # Invoke the model on Bedrock
            response = bedrock_runtime.invoke_model(
                modelId="us.amazon.nova-premier-v1:0",
                body=json.dumps(payload)
            )
            
            # Parse and return the response
            response_body = json.loads(response["body"].read())
            
            # Extract text content from Nova's response
            content_text = response_body["output"]["message"]["content"][0]["text"]
            return content_text
        
        except ClientError as e:
            return f"L·ªói khi g·ªçi Bedrock model: {str(e)}"
        except Exception as e:
            return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"

def analyze_frames_with_claude(frames, prompt: str, temperature: float, top_p: float, top_k: int, max_tokens: int):
    """
    Uses Claude 3.7 Sonnet on AWS Bedrock to analyze video frames and count different types of products.
    
    Args:
        frames: List of video frames to analyze
        prompt: Custom prompt for Claude
        temperature: Temperature setting (0-1)
        top_p: Top-p setting (0-1)
        top_k: Top-k setting
        max_tokens: Maximum tokens in response
        
    Returns:
        Claude's analysis of the video frame content
    """
    
    # Create placeholder for loading indicator
    with st.spinner("Claude ƒëang ph√¢n t√≠ch frames t·ª´ video..."):
        # Read and encode frames
        images = []
        for i, (_, frame) in enumerate(frames):
            # Encode to base64
            image_data, mime_type = image_to_base64(frame, f"frame_{i}.jpg")
                
            images.append({
                "type": "image",
                "source": {
                    "type": "base64",
                    "media_type": f"image/{mime_type}",
                    "data": image_data
                }
            })
        
        # Prepare the message content combining images and prompt
        message_content = images + [{"type": "text", "text": prompt}]
        
        # Prepare the request payload for Bedrock
        payload = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "top_k": top_k,
            "messages": [
                {
                    "role": "user",
                    "content": message_content
                }
            ]
        }
        
        try:
            # Create a Bedrock Runtime client
            # Use AWS credentials from environment variables or AWS configuration
            bedrock_runtime = boto3.client(
                service_name="bedrock-runtime",
                region_name=DEFAULT_REGION
            )
            
            # Invoke the model on Bedrock
            response = bedrock_runtime.invoke_model(
                modelId="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
                body=json.dumps(payload)
            )
            
            # Parse and return the response
            response_body = json.loads(response["body"].read())
            return response_body["content"][0]["text"]
        
        except ClientError as e:
            return f"L·ªói khi g·ªçi Bedrock model: {str(e)}"
        except Exception as e:
            return f"L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"

def main():
    # App title
    st.title("Ph√¢n T√≠ch Video S·∫£n Ph·∫©m V·ªõi Bedrock")
    
    # Information block
    st.info("""
    ·ª®ng d·ª•ng n√†y s·ª≠ d·ª•ng Amazon Nova v√† Claude tr√™n AWS Bedrock ƒë·ªÉ ph√¢n t√≠ch video s·∫£n ph·∫©m.
    T·∫£i l√™n video v√† ch·ªçn ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t frames ƒë·ªÉ Nova ho·∫∑c Claude ph√¢n t√≠ch s·∫£n ph·∫©m.
    """)
    
    # Sidebar for model parameters only (removed AWS configuration)
    st.sidebar.title("C·∫•u h√¨nh")
    
    # Model selection
    st.sidebar.subheader("Ch·ªçn Model")
    selected_model = st.sidebar.radio(
        "Model:",
        options=[ModelType.NOVA, ModelType.CLAUDE],
        format_func=lambda x: x.value
    )
    
    # Model Parameters section
    st.sidebar.subheader("Tham S·ªë Model")
    
    temperature = st.sidebar.slider(
        "Temperature:", 
        min_value=0.0,
        max_value=1.0,
        value=DEFAULT_TEMPERATURE,
        step=0.05,
        help="Ki·ªÉm so√°t m·ª©c ƒë·ªô ng·∫´u nhi√™n trong ƒë·∫ßu ra. Gi√° tr·ªã 0 s·∫Ω cho k·∫øt qu·∫£ nh·∫•t qu√°n, gi√° tr·ªã cao h∆°n t·∫°o nhi·ªÅu bi·∫øn th·ªÉ."
    )
    
    top_p = st.sidebar.slider(
        "Top P:",
        min_value=0.0,
        max_value=1.0,
        value=DEFAULT_TOP_P,
        step=0.05,
        help="Ki·ªÉm so√°t ƒëa d·∫°ng th√¥ng qua nucleus sampling. 1.0 = kh√¥ng h·∫°n ch·∫ø, 0.5 = ch·ªâ xem x√©t tokens trong top 50% x√°c su·∫•t."
    )
    
    top_k = st.sidebar.slider(
        "Top K:",
        min_value=0,
        max_value=500,
        value=DEFAULT_TOP_K,
        step=10,
        help="Gi·ªõi h·∫°n s·ªë tokens ƒë∆∞·ª£c xem x√©t khi t·∫°o ƒë·∫ßu ra. 0 = kh√¥ng s·ª≠ d·ª•ng top_k."
    )
    
    max_tokens = st.sidebar.slider(
        "Max Tokens:",
        min_value=100,
        max_value=10000,
        value=DEFAULT_MAX_TOKENS,
        step=100,
        help="ƒê·ªô d√†i t·ªëi ƒëa c·ªßa ph·∫£n h·ªìi ƒë∆∞·ª£c t·∫°o ra."
    )
    
    # Prompt configuration section
    st.sidebar.subheader("T√πy Ch·ªânh Prompt")
    
    # Option to use custom prompt
    use_custom_prompt = st.sidebar.checkbox("S·ª≠ d·ª•ng prompt t√πy ch·ªânh", value=False)
    
    if use_custom_prompt:
        prompt = st.sidebar.text_area("Nh·∫≠p prompt c·ªßa b·∫°n:", DEFAULT_PROMPT, height=300)
    else:
        prompt = DEFAULT_PROMPT
        st.sidebar.markdown("*ƒêang s·ª≠ d·ª•ng prompt m·∫∑c ƒë·ªãnh*")
    
    # Main content area
    # File uploader for video
    st.subheader("T·∫£i l√™n video s·∫£n ph·∫©m")
    uploaded_video = st.file_uploader(
        "Ch·ªçn file video (MP4, MOV, AVI, etc.)",
        type=["mp4", "mov", "avi", "mkv", "wmv"],
    )
    
    # Video frame extraction settings
    st.subheader("C√†i ƒë·∫∑t tr√≠ch xu·∫•t frames")
    
    extraction_method = st.radio(
        "Ph∆∞∆°ng ph√°p tr√≠ch xu·∫•t frames:",
        ["ƒê·ªÅu ƒë·∫∑n theo s·ªë l∆∞·ª£ng", "Theo kho·∫£ng th·ªùi gian", "T·ª± ƒë·ªông ph√°t hi·ªán keyframes"]
    )
    
    # Show different settings based on extraction method
    if extraction_method == "ƒê·ªÅu ƒë·∫∑n theo s·ªë l∆∞·ª£ng":
        num_frames = st.slider(
            "S·ªë l∆∞·ª£ng frames c·∫ßn tr√≠ch xu·∫•t:",
            min_value=5,
            max_value=100,
            value=10,
            step=1
        )
    elif extraction_method == "Theo kho·∫£ng th·ªùi gian":
        interval_seconds = st.slider(
            "Kho·∫£ng th·ªùi gian gi·ªØa c√°c frames (gi√¢y):",
            min_value=0.5,
            max_value=10.0,
            value=2.0,
            step=0.5
        )
    else:  # T·ª± ƒë·ªông ph√°t hi·ªán keyframes
        threshold = st.slider(
            "Ng∆∞·ª°ng ph√°t hi·ªán keyframes:",
            min_value=0.01,
            max_value=0.5,
            value=0.1,
            step=0.01,
            help="Gi√° tr·ªã c√†ng th·∫•p, c√†ng nhi·ªÅu frames ƒë∆∞·ª£c ph√°t hi·ªán"
        )
        max_keyframes = st.slider(
            "S·ªë l∆∞·ª£ng keyframes t·ªëi ƒëa:",
            min_value=5,
            max_value=30,
            value=15,
            step=1
        )
    
    # Show video and process it
    if uploaded_video:
        st.video(uploaded_video)
        
        # Button to extract frames and analyze
        if st.button("Tr√≠ch xu·∫•t frames v√† ph√¢n t√≠ch", type="primary"):
            # Process the video to extract frames
            video_processor = VideoProcessor(uploaded_video)
            video_info = video_processor.get_video_info()
            
            # Display video info
            st.subheader("Th√¥ng tin video")
            st.write(f"T√™n file: {video_info['filename']}")
            st.write(f"ƒê·ªô ph√¢n gi·∫£i: {video_info['resolution'][0]} x {video_info['resolution'][1]}")
            st.write(f"FPS: {video_info['fps']:.2f}")
            st.write(f"Th·ªùi l∆∞·ª£ng: {video_info['duration']:.2f} gi√¢y")
            st.write(f"T·ªïng s·ªë frames: {video_info['frame_count']}")
            
            # Extract frames based on selected method
            with st.spinner("ƒêang tr√≠ch xu·∫•t frames t·ª´ video..."):
                if extraction_method == "ƒê·ªÅu ƒë·∫∑n theo s·ªë l∆∞·ª£ng":
                    frames = video_processor.extract_frames_uniform(num_frames)
                    st.write(f"ƒê√£ tr√≠ch xu·∫•t {len(frames)} frames ph√¢n b·ªë ƒë·ªÅu")
                elif extraction_method == "Theo kho·∫£ng th·ªùi gian":
                    frames = video_processor.extract_frames_interval(interval_seconds)
                    st.write(f"ƒê√£ tr√≠ch xu·∫•t {len(frames)} frames (m·ªói {interval_seconds} gi√¢y)")
                else:  # T·ª± ƒë·ªông ph√°t hi·ªán keyframes
                    frames = video_processor.extract_frames_keyframes(threshold, max_keyframes)
                    st.write(f"ƒê√£ ph√°t hi·ªán v√† tr√≠ch xu·∫•t {len(frames)} keyframes")
            
            # Display extracted frames with expander for show/hide
            st.subheader("Frames ƒë√£ tr√≠ch xu·∫•t")
            
            # L∆∞u frames ƒë·ªÉ ph√¢n t√≠ch (lu√¥n th·ª±c hi·ªán)
            extracted_frames = [(i, frame.image) for i, frame in enumerate(frames)]
            
            # Hi·ªÉn th·ªã th√¥ng tin t·ªïng quan v·ªÅ frames
            st.info(f"ƒê√£ tr√≠ch xu·∫•t {len(frames)} frames.")
            
            # S·ª≠ d·ª•ng expander ƒë·ªÉ hi·ªÉn th·ªã/·∫©n frames (kh√¥ng g√¢y reload to√†n b·ªô trang)
            with st.expander("Xem chi ti·∫øt c√°c frames", expanded=False):
                # Th√™m t√πy ch·ªçn xem ki·ªÉu l∆∞·ªõi ho·∫∑c danh s√°ch
                view_mode = st.radio(
                    "Ch·∫ø ƒë·ªô hi·ªÉn th·ªã:",
                    ["L∆∞·ªõi", "Danh s√°ch"]
                )
                
                if view_mode == "L∆∞·ªõi":
                    # Create columns to display frames in grid
                    num_cols = 4  # Number of columns in the grid
                    cols = st.columns(num_cols)
                    
                    # Hi·ªÉn th·ªã c√°c frames ƒë√£ tr√≠ch xu·∫•t theo l∆∞·ªõi
                    for i, frame in enumerate(frames):
                        col_idx = i % num_cols
                        with cols[col_idx]:
                            # Hi·ªÉn th·ªã frame
                            st.image(
                                frame.image, 
                                caption=f"Frame {frame.frame_number} (t={frame.timestamp:.2f}s)", 
                                use_column_width=True
                            )
                else:  # Danh s√°ch
                    # T·∫°o container ƒë·ªÉ ƒë·∫∑t t·∫•t c·∫£ c√°c expander b√™n trong
                    frame_container = st.container()
                    # Hi·ªÉn th·ªã theo danh s√°ch t·ª´ng frame m·ªôt
                    for i, frame in enumerate(frames):
                        with frame_container.expander(f"Frame {frame.frame_number} (t={frame.timestamp:.2f}s)"):
                            st.image(frame.image, use_column_width=True)
            
            # Ph√¢n t√≠ch frames b·∫±ng Nova ho·∫∑c Claude
            if extracted_frames:
                if selected_model == ModelType.NOVA:
                    # Call Nova via AWS Bedrock
                    result = analyze_frames_with_nova(
                        extracted_frames, 
                        prompt, 
                        temperature, 
                        top_p, 
                        top_k, 
                        max_tokens
                    )
                else:  # Claude
                    # Call Claude via AWS Bedrock
                    result = analyze_frames_with_claude(
                        extracted_frames, 
                        prompt, 
                        temperature, 
                        top_p, 
                        top_k, 
                        max_tokens
                    )
                
                # Display results
                st.subheader(f"K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ {selected_model.value}")
                st.markdown(result)
                
                # Option to download as text file
                if result:
                    # Create download button for the result
                    st.download_button(
                        label="T·∫£i k·∫øt qu·∫£ v·ªÅ (TXT)",
                        data=result,
                        file_name="ket_qua_phan_tich.txt",
                        mime="text/plain"
                    )
                    
                    # Save prompt used for reference
                    st.download_button(
                        label="T·∫£i prompt ƒë√£ s·ª≠ d·ª•ng (TXT)",
                        data=prompt,
                        file_name="prompt_da_su_dung.txt",
                        mime="text/plain"
                    )
    else:
        st.write("üëÜ H√£y t·∫£i l√™n video ƒë·ªÉ ph√¢n t√≠ch")

if __name__ == "__main__":
    main()